{
    "__version": 10,
    "training_method": "LORA",
    "model_type": "Z_IMAGE",
    "debug_mode": false,
    "debug_dir": "debug",
    "workspace_dir": "workspace/run",
    "cache_dir": "workspace-cache/run",
    "tensorboard": true,
    "tensorboard_expose": true,
    "tensorboard_always_on": true,
    "tensorboard_port": 6006,
    "validation": true,
    "validate_after": 1,
    "validate_after_unit": "EPOCH",
    "continue_last_backup": true,
    "prevent_overwrites": false,
    "include_train_config": "NONE",
    "multi_gpu": false,
    "device_indexes": "",
    "gradient_reduce_precision": "FLOAT_32_STOCHASTIC",
    "fused_gradient_reduce": true,
    "async_gradient_reduce": true,
    "async_gradient_reduce_buffer": 100,
    "base_model_name": "Tongyi-MAI/Z-Image",
    "output_dtype": "FLOAT_32",
    "output_model_format": "SAFETENSORS",
    "output_model_destination": "models/model.safetensors",
    "gradient_checkpointing": "ON",
    "enable_async_offloading": true,
    "enable_activation_offloading": true,
    "layer_offload_fraction": 0.0,
    "force_circular_padding": false,
    "compile": false,
    "concept_file_name": "training_concepts/concepts.json",
    "concepts": [
        {
            "__version": 2,
            "image": {
                "__version": 0,
                "enable_crop_jitter": true,
                "enable_random_flip": false,
                "enable_fixed_flip": false,
                "enable_random_rotate": false,
                "enable_fixed_rotate": false,
                "random_rotate_max_angle": 0.0,
                "enable_random_brightness": false,
                "enable_fixed_brightness": false,
                "random_brightness_max_strength": 0.0,
                "enable_random_contrast": false,
                "enable_fixed_contrast": false,
                "random_contrast_max_strength": 0.0,
                "enable_random_saturation": false,
                "enable_fixed_saturation": false,
                "random_saturation_max_strength": 0.0,
                "enable_random_hue": false,
                "enable_fixed_hue": false,
                "random_hue_max_strength": 0.0,
                "enable_resolution_override": false,
                "resolution_override": "512",
                "enable_random_circular_mask_shrink": false,
                "enable_random_mask_rotate_crop": false
            },
            "text": {
                "__version": 0,
                "prompt_source": "sample",
                "prompt_path": "",
                "enable_tag_shuffling": true,
                "tag_delimiter": ",",
                "keep_tags_count": 1,
                "tag_dropout_enable": true,
                "tag_dropout_mode": "RANDOM",
                "tag_dropout_probability": 0.2,
                "tag_dropout_special_tags_mode": "NONE",
                "tag_dropout_special_tags": "",
                "tag_dropout_special_tags_regex": false,
                "caps_randomize_enable": false,
                "caps_randomize_mode": "capslock, title, first, random",
                "caps_randomize_probability": 0.0,
                "caps_randomize_lowercase": false
            },
            "name": "shunying_zimage",
            "path": "/workspace/dataset/zimage_train",
            "seed": -683562741,
            "enabled": true,
            "type": "STANDARD",
            "include_subdirectories": false,
            "image_variations": 1,
            "text_variations": 5,
            "balancing": 1.0,
            "balancing_strategy": "REPEATS",
            "loss_weight": 1.0
        },
        {
            "__version": 2,
            "image": {
                "__version": 0,
                "enable_crop_jitter": false,
                "enable_random_flip": false,
                "enable_fixed_flip": false,
                "enable_random_rotate": false,
                "enable_fixed_rotate": false,
                "random_rotate_max_angle": 0.0,
                "enable_random_brightness": false,
                "enable_fixed_brightness": false,
                "random_brightness_max_strength": 0.0,
                "enable_random_contrast": false,
                "enable_fixed_contrast": false,
                "random_contrast_max_strength": 0.0,
                "enable_random_saturation": false,
                "enable_fixed_saturation": false,
                "random_saturation_max_strength": 0.0,
                "enable_random_hue": false,
                "enable_fixed_hue": false,
                "random_hue_max_strength": 0.0,
                "enable_resolution_override": false,
                "resolution_override": "512",
                "enable_random_circular_mask_shrink": false,
                "enable_random_mask_rotate_crop": false
            },
            "text": {
                "__version": 0,
                "prompt_source": "sample",
                "prompt_path": "",
                "enable_tag_shuffling": false,
                "tag_delimiter": ",",
                "keep_tags_count": 1,
                "tag_dropout_enable": false,
                "tag_dropout_mode": "FULL",
                "tag_dropout_probability": 0.0,
                "tag_dropout_special_tags_mode": "NONE",
                "tag_dropout_special_tags": "",
                "tag_dropout_special_tags_regex": false,
                "caps_randomize_enable": false,
                "caps_randomize_mode": "capslock, title, first, random",
                "caps_randomize_probability": 0.0,
                "caps_randomize_lowercase": false
            },
            "name": "shunying_zimage_val",
            "path": "/workspace/dataset/zimage_val",
            "seed": 812441888,
            "enabled": true,
            "type": "VALIDATION",
            "include_subdirectories": false,
            "image_variations": 1,
            "text_variations": 1,
            "balancing": 1.0,
            "balancing_strategy": "REPEATS",
            "loss_weight": 1.0
        }
    ],
    "aspect_ratio_bucketing": true,
    "latent_caching": true,
    "clear_cache_before_training": true,
    "learning_rate_scheduler": "COSINE",
    "custom_learning_rate_scheduler": null,
    "scheduler_params": [],
    "learning_rate": 1.0,
    "learning_rate_warmup_steps": 0.0,
    "learning_rate_cycles": 1.0,
    "learning_rate_min_factor": 0.0,
    "epochs": 10000,
    "batch_size": 1,
    "gradient_accumulation_steps": 4,
    "ema": "OFF",
    "ema_decay": 0.999,
    "ema_update_step_interval": 5,
    "dataloader_threads": 1,
    "train_device": "cuda",
    "temp_device": "cpu",
    "train_dtype": "BFLOAT_16",
    "fallback_train_dtype": "BFLOAT_16",
    "enable_autocast_cache": true,
    "only_cache": false,
    "resolution": "1024,1280,1536",
    "frames": "25",
    "mse_strength": 1.0,
    "mae_strength": 0.0,
    "log_cosh_strength": 0.0,
    "huber_strength": 0.0,
    "huber_delta": 1.0,
    "vb_loss_strength": 1.0,
    "loss_weight_fn": "MIN_SNR_GAMMA",
    "loss_weight_strength": 5.0,
    "dropout_probability": 0.0,
    "loss_scaler": "NONE",
    "learning_rate_scaler": "NONE",
    "clip_grad_norm": 100.0,
    "offset_noise_weight": 0.0,
    "generalized_offset_noise": false,
    "perturbation_noise_weight": 0.0,
    "rescale_noise_scheduler_to_zero_terminal_snr": false,
    "force_v_prediction": false,
    "force_epsilon_prediction": false,
    "min_noising_strength": 0.0,
    "max_noising_strength": 1.0,
    "timestep_distribution": "LOGIT_NORMAL",
    "noising_weight": 0.0,
    "noising_bias": 0.0,
    "timestep_shift": 3.0,
    "dynamic_timestep_shifting": false,
    "cep_enabled": true,
    "cep_gamma": 1.0,
    "unet": {
        "__version": 0,
        "model_name": "",
        "include": true,
        "train": true,
        "stop_training_after": 0,
        "stop_training_after_unit": "NEVER",
        "learning_rate": null,
        "weight_dtype": "FLOAT_32",
        "dropout_probability": 0.0,
        "train_embedding": true,
        "attention_mask": false,
        "guidance_scale": 1.0
    },
    "transformer": {
        "__version": 0,
        "model_name": "",
        "include": true,
        "train": true,
        "stop_training_after": 0,
        "stop_training_after_unit": "NEVER",
        "learning_rate": null,
        "weight_dtype": "BFLOAT_16",
        "dropout_probability": 0.0,
        "train_embedding": true,
        "attention_mask": false,
        "guidance_scale": 1.0
    },
    "quantization": {
        "__version": 0,
        "layer_filter": "layers",
        "layer_filter_preset": "blocks",
        "layer_filter_regex": false,
        "svd_dtype": "NONE",
        "svd_rank": 16,
        "cache_dir": null
    },
    "text_encoder": {
        "__version": 0,
        "model_name": "",
        "include": true,
        "train": false,
        "stop_training_after": 30,
        "stop_training_after_unit": "EPOCH",
        "learning_rate": null,
        "weight_dtype": "BFLOAT_16",
        "dropout_probability": 0.0,
        "train_embedding": true,
        "attention_mask": false,
        "guidance_scale": 1.0
    },
    "text_encoder_layer_skip": 0,
    "text_encoder_sequence_length": 512,
    "text_encoder_2": {
        "__version": 0,
        "model_name": "",
        "include": true,
        "train": false,
        "stop_training_after": 30,
        "stop_training_after_unit": "EPOCH",
        "learning_rate": null,
        "weight_dtype": "FLOAT_32",
        "dropout_probability": 0.0,
        "train_embedding": true,
        "attention_mask": false,
        "guidance_scale": 1.0
    },
    "text_encoder_2_layer_skip": 0,
    "text_encoder_2_sequence_length": 77,
    "vae": {
        "__version": 0,
        "model_name": "",
        "include": true,
        "train": false,
        "stop_training_after": null,
        "stop_training_after_unit": "NEVER",
        "learning_rate": null,
        "weight_dtype": "FLOAT_32",
        "dropout_probability": 0.0,
        "train_embedding": true,
        "attention_mask": false,
        "guidance_scale": 1.0
    },
    "masked_training": false,
    "unmasked_probability": 0.1,
    "unmasked_weight": 0.1,
    "normalize_masked_area_loss": false,
    "masked_prior_preservation_weight": 0.0,
    "custom_conditioning_image": false,
    "layer_filter": "^(?=.*attention)(?!.*refiner).*,^(?=.*feed_forward)(?!.*refiner).*",
    "layer_filter_preset": "attn-mlp",
    "layer_filter_regex": true,
    "embedding_learning_rate": null,
    "preserve_embedding_norm": false,
    "embedding": {
        "__version": 0,
        "uuid": "974e4e5a-07d5-413d-8f9d-24715c145e4d",
        "model_name": "",
        "placeholder": "<embedding>",
        "train": true,
        "stop_training_after": null,
        "stop_training_after_unit": "NEVER",
        "token_count": 1,
        "initial_embedding_text": "*",
        "is_output_embedding": false
    },
    "additional_embeddings": [],
    "embedding_weight_dtype": "FLOAT_32",
    "peft_type": "LORA",
    "lora_model_name": "",
    "lora_rank": 16,
    "lora_alpha": 1.0,
    "lora_decompose": false,
    "lora_decompose_norm_epsilon": true,
    "lora_decompose_output_axis": false,
    "lora_weight_dtype": "FLOAT_32",
    "bundle_additional_embeddings": true,
    "oft_block_size": 32,
    "oft_coft": false,
    "coft_eps": 0.0001,
    "oft_block_share": false,
    "optimizer": {
        "__version": 0,
        "optimizer": "PRODIGY_ADV",
        "adam_w_mode": false,
        "alpha": 5.0,
        "amsgrad": false,
        "beta1": 0.999,
        "beta2": 0.999,
        "beta3": null,
        "bias_correction": false,
        "block_wise": false,
        "capturable": false,
        "centered": false,
        "clip_threshold": null,
        "d0": 0.0001,
        "d_coef": 1.0,
        "dampening": null,
        "decay_rate": null,
        "decouple": false,
        "differentiable": false,
        "eps": 1E-8,
        "eps2": null,
        "foreach": false,
        "fsdp_in_use": false,
        "fused": false,
        "fused_back_pass": false,
        "growth_rate": "inf",
        "initial_accumulator_value": null,
        "initial_accumulator": null,
        "is_paged": false,
        "log_every": null,
        "lr_decay": null,
        "max_unorm": null,
        "maximize": false,
        "min_8bit_size": null,
        "quant_block_size": null,
        "momentum": null,
        "nesterov": false,
        "no_prox": false,
        "optim_bits": null,
        "percentile_clipping": null,

        "relative_step": false,
        "safeguard_warmup": false,
        "scale_parameter": false,
        "stochastic_rounding": true,
        "use_bias_correction": false,
        "use_triton": false,
        "warmup_init": false,
        "weight_decay": 0.01,
        "weight_lr_power": null,
        "decoupled_decay": false,
        "fixed_decay": false,
        "rectify": false,
        "degenerated_to_sgd": false,
        "k": null,
        "xi": null,
        "n_sma_threshold": null,
        "ams_bound": false,
        "adanorm": false,
        "adam_debias": false,
        "slice_p": 11,
        "cautious": false,
        "weight_decay_by_lr": true,
        "prodigy_steps": 0,
        "use_speed": false,
        "split_groups": true,
        "split_groups_mean": true,
        "factored": false,
        "factored_fp32": true,
        "use_stableadamw": true,
        "use_cautious": false,
        "use_grams": false,
        "use_adopt": false,
        "d_limiter": false,
        "use_schedulefree": false,
        "use_orthograd": true,
        "nnmf_factor": false,
        "orthogonal_gradient": true,
        "use_atan2": false,
        "use_AdEMAMix": false,
        "beta3_ema": 0.9999,
        "alpha_grad": 100.0,
        "beta1_warmup": null,
        "min_beta1": null,
        "Simplified_AdEMAMix": true,
        "cautious_mask": false,
        "grams_moment": false,
        "kourkoutas_beta": true,
        "k_warmup_steps": 50,
        "schedulefree_c": null,
        "ns_steps": null,
        "MuonWithAuxAdam": false,
        "muon_hidden_layers": null,
        "muon_adam_regex": false,
        "muon_adam_lr": null,
        "muon_te1_adam_lr": null,
        "muon_te2_adam_lr": null,
        "muon_adam_config": {},
        "rms_rescaling": true,
        "normuon_variant": false,
        "beta2_normuon": null,
        "normuon_eps": null,
        "low_rank_ortho": false,
        "ortho_rank": null,
        "accelerated_ns": false,
        "cautious_wd": true,
        "approx_mars": false,
        "kappa_p": null,
        "auto_kappa_p": false,
        "compile": false
    },
    "sample_definition_file_name": "training_samples/samples.json",
    "samples": [
        {
            "__version": 0,
            "enabled": true,
            "prompt": "shunying, a young Asian woman standing at the edge of a wooden pier overlooking a calm lake at golden hour. She wears a cream-colored linen dress, her long black hair catching the warm breeze. Soft golden light reflects off the water surface, casting a gentle glow across her face. The background shows distant mountains fading into a warm haze.\n\n",
            "negative_prompt": "",
            "height": 1024,
            "width": 1024,
            "frames": 1,
            "length": 10.0,
            "seed": 0,
            "random_seed": false,
            "diffusion_steps": 50,
            "cfg_scale": 4.0,
            "noise_scheduler": "EULER",
            "text_encoder_1_layer_skip": 0,
            "text_encoder_1_sequence_length": null,
            "text_encoder_2_layer_skip": 0,
            "text_encoder_2_sequence_length": null,
            "text_encoder_3_layer_skip": 0,
            "text_encoder_4_layer_skip": 0,
            "transformer_attention_mask": false,
            "force_last_timestep": false,
            "sample_inpainting": false,
            "base_image_path": "",
            "mask_image_path": ""
        },
        {
            "__version": 0,
            "enabled": true,
            "prompt": "shunying, a young Asian woman sitting in a modern caf√©, reading a book with one hand resting on a ceramic coffee cup. She wears a tailored charcoal blazer over a white turtleneck. Natural daylight pours through floor-to-ceiling windows, creating soft shadows across the marble tabletop. Shallow depth of field with warm interior tones.\n\n",
            "negative_prompt": "",
            "height": 1024,
            "width": 1024,
            "frames": 1,
            "length": 10.0,
            "seed": 1,
            "random_seed": false,
            "diffusion_steps": 50,
            "cfg_scale": 4.0,
            "noise_scheduler": "EULER",
            "text_encoder_1_layer_skip": 0,
            "text_encoder_1_sequence_length": null,
            "text_encoder_2_layer_skip": 0,
            "text_encoder_2_sequence_length": null,
            "text_encoder_3_layer_skip": 0,
            "text_encoder_4_layer_skip": 0,
            "transformer_attention_mask": false,
            "force_last_timestep": false,
            "sample_inpainting": false,
            "base_image_path": "",
            "mask_image_path": ""
        },
        {
            "__version": 0,
            "enabled": true,
            "prompt": "shunying, close-up portrait of a young Asian woman illuminated by neon signs at night on a rain-soaked city street. Her long black hair is slightly damp, and she gazes directly into the camera with a calm expression. Cyan and magenta reflections shimmer across her skin and the wet pavement behind her. Cinematic night photography with bokeh highlights.\n\n",
            "negative_prompt": "",
            "height": 1024,
            "width": 1024,
            "frames": 1,
            "length": 10.0,
            "seed": 2,
            "random_seed": false,
            "diffusion_steps": 50,
            "cfg_scale": 4.0,
            "noise_scheduler": "EULER",
            "text_encoder_1_layer_skip": 0,
            "text_encoder_1_sequence_length": null,
            "text_encoder_2_layer_skip": 0,
            "text_encoder_2_sequence_length": null,
            "text_encoder_3_layer_skip": 0,
            "text_encoder_4_layer_skip": 0,
            "transformer_attention_mask": false,
            "force_last_timestep": false,
            "sample_inpainting": false,
            "base_image_path": "",
            "mask_image_path": ""
        },
        {
            "__version": 0,
            "enabled": true,
            "prompt": "shunying, a young Asian woman walking through a sunlit autumn park, wearing an oversized camel coat, dark jeans, and white sneakers. Fallen golden leaves scatter along the path around her. She carries a canvas tote bag over one shoulder and smiles slightly. Soft diffused afternoon light filters through the canopy of orange and red trees.\n\n",
            "negative_prompt": "",
            "height": 1024,
            "width": 1024,
            "frames": 1,
            "length": 10.0,
            "seed": 3,
            "random_seed": false,
            "diffusion_steps": 50,
            "cfg_scale": 4.0,
            "noise_scheduler": "EULER",
            "text_encoder_1_layer_skip": 0,
            "text_encoder_1_sequence_length": null,
            "text_encoder_2_layer_skip": 0,
            "text_encoder_2_sequence_length": null,
            "text_encoder_3_layer_skip": 0,
            "text_encoder_4_layer_skip": 0,
            "transformer_attention_mask": false,
            "force_last_timestep": false,
            "sample_inpainting": false,
            "base_image_path": "",
            "mask_image_path": ""
        },
        {
            "__version": 0,
            "enabled": true,
            "prompt": "shunying, a young Asian woman in an elegant black evening dress, standing in a dimly lit gallery with large abstract paintings on white walls behind her. Her long black hair is styled in a loose updo. She holds a glass of champagne and looks over her shoulder toward the camera. Dramatic side lighting creates deep shadows and highlights the fabric texture of her dress.\n\n",
            "negative_prompt": "",
            "height": 1024,
            "width": 1024,
            "frames": 1,
            "length": 10.0,
            "seed": 4,
            "random_seed": false,
            "diffusion_steps": 50,
            "cfg_scale": 4.0,
            "noise_scheduler": "EULER",
            "text_encoder_1_layer_skip": 0,
            "text_encoder_1_sequence_length": null,
            "text_encoder_2_layer_skip": 0,
            "text_encoder_2_sequence_length": null,
            "text_encoder_3_layer_skip": 0,
            "text_encoder_4_layer_skip": 0,
            "transformer_attention_mask": false,
            "force_last_timestep": false,
            "sample_inpainting": false,
            "base_image_path": "",
            "mask_image_path": ""
        }
    ],
    "sample_after": 250,
    "sample_after_unit": "STEP",
    "sample_skip_first": 1,
    "sample_image_format": "PNG",
    "sample_video_format": "MP4",
    "sample_audio_format": "MP3",
    "samples_to_tensorboard": true,
    "non_ema_sampling": true,
    "backup_after": 250,
    "backup_after_unit": "STEP",
    "rolling_backup": true,
    "rolling_backup_count": 3,
    "backup_before_save": true,
    "save_every": 250,
    "save_every_unit": "STEP",
    "save_skip_first": 0,
    "save_filename_prefix": "shunying_zimage"
}